{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found most of the streaming portion of this at http://adilmoujahid.com/posts/2014/07/twitter-analytics/\n",
    "\n",
    "This file below is saved as \"twitter_streaming.py\" in my folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "\n",
    "access_token = \"-\"\n",
    "access_token_secret = \"-\"\n",
    "consumer_key = \"-\"\n",
    "consumer_secret = \"-\"\n",
    "\n",
    "\n",
    "#This is a basic listener that just prints received tweets to stdout.\n",
    "class StdOutListener(StreamListener):\n",
    "\n",
    "    def on_data(self, data):\n",
    "        print(data)\n",
    "        return True\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    #This handles Twitter authetification and the connection to Twitter Streaming API\n",
    "    l = StdOutListener()\n",
    "    auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    stream = Stream(auth, l)\n",
    "\n",
    "    #This line filter Twitter Streams to capture data by the keywords:\n",
    "    stream.filter(track=['#kateswall', '#katesteinle', '#steinle'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I run the command \"python twitter_streaming.py > twitter_data.txt\" in the terminal to run the above file and save the output to a new text file called \"twitter_data.txt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "tweets_data_path = '/Users/Marty/Documents/BMKT670/TwitterAPI/twitter_data.txt'\n",
    "\n",
    "tweets_data = []\n",
    "tweets_file = open(tweets_data_path, \"r\")\n",
    "for line in tweets_file:\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "        tweets_data.append(tweet)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "print(len(tweets_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is my own custom code that implements the spaCy library to run analysis of the Kate Steinel tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#spacy is a framework that allows\n",
    "#deep dives into nlp in a variety of ways\n",
    "import spacy\n",
    "#This is a HUGE lexicon of words\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#initialize tweets list we will pull from json\n",
    "tweets_list = []\n",
    "with open('/Users/Marty/Documents/BMKT670/TwitterAPI/twitter_data.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            #json saved as huge dictionary of dictionaries\n",
    "            #this was very hard to figure out\n",
    "            tweet = json.loads(line)\n",
    "            tweets_list.append(tweet)\n",
    "        except:\n",
    "            #catches any key errors we might run into\n",
    "            KeyError\n",
    "    #print(json.dumps(tweet, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_tweet_list = []\n",
    "for tweet in tweets_list:\n",
    "    #check if tweet is a retweet or not\n",
    "    #we want to pull original tweets first\n",
    "    if \"retweeted_status\" not in tweet:\n",
    "        #adds UserName, # of followers and friends, tweet text, and nlp version of tweet\n",
    "        temp_list = [tweet[\"user\"][\"name\"], tweet[\"user\"][\"followers_count\"], \n",
    "                     tweet[\"user\"][\"friends_count\"], str(tweet[\"text\"]), nlp(tweet[\"text\"])]\n",
    "        final_tweet_list.append(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1942\n"
     ]
    }
   ],
   "source": [
    "print(len(final_tweet_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell does most of the heavy lifting for this project.\n",
    "It runs through the tweet list, and creates a list that I can use for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "21000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "60000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "92000\n",
      "93000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "108000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "128000\n",
      "130000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "141000\n",
      "143000\n",
      "145000\n",
      "146000\n",
      "149000\n",
      "151000\n",
      "152000\n",
      "153000\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "#List and set for tweets with similarity > .95\n",
    "sim_list = []\n",
    "sim_set = set()\n",
    "#List and set for tweets with similarity between .9 and .95\n",
    "sim_list_2 = []\n",
    "sim_set_2 = set()\n",
    "for tweet in final_tweet_list:\n",
    "    for other_tweet in final_tweet_list:\n",
    "        #Find the similarity score between each tweet in the list\n",
    "        if (tweet[3] != other_tweet[3] and tweet[4].similarity(other_tweet[4]) > .95):\n",
    "            counter += 1\n",
    "            #This code creates the parts of speech for each tweet and other tweet\n",
    "            tweet_pos = \" \".join([word.pos_ for word in tweet[4]])\n",
    "            other_tweet_pos = \" \".join([word.pos_ for word in other_tweet[4]])\n",
    "            #Build the temporary list to add to the main list\n",
    "                #Maybe not best practice?\n",
    "            temp_list = [tweet[0:4], tweet_pos, other_tweet[0:4], \n",
    "                             other_tweet_pos, tweet[4].similarity(other_tweet[4])]\n",
    "            sim_list.append(temp_list)\n",
    "            sim_set.add(tweet[3])\n",
    "            sim_set.add(tweet[4])\n",
    "        #Find slightly looser similarity score and repeat above\n",
    "        elif (tweet[3] != other_tweet[3] and .95 > tweet[4].similarity(other_tweet[4]) > .90):\n",
    "            counter += 1\n",
    "            tweet_pos = \" \".join([word.pos_ for word in tweet[4]])\n",
    "            other_tweet_pos = \" \".join([word.pos_ for word in other_tweet[4]])\n",
    "            temp_list = [tweet[0:4], tweet_pos, other_tweet[0:4], \n",
    "                             other_tweet_pos, tweet[4].similarity(other_tweet[4])]\n",
    "            sim_list_2.append(temp_list)\n",
    "            sim_set_2.add(tweet[3])\n",
    "            sim_set_2.add(tweet[4])\n",
    "            #Counter to check progress\n",
    "            if counter % 1000 == 0:\n",
    "                print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Zod Than√°tos\n",
      "Followers: 32\n",
      "Friends: 99\n",
      "Parts of Speech: PUNCT NOUN SYM PROPN SPACE SYM PROPN X\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">@FoxNews \n",
       "<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    @GovMikeHuckabee #\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    KateSteinle\n",
       "#SanctuaryCities https://t.co/YCIsFsC8aX\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: OneCoast\n",
      "Followers: 430\n",
      "Friends: 1012\n",
      "Parts of Speech: VERB SYM VERB SYM PROPN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    @KTVU #BoycottSanFrancisco #\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    KateSteinle\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 0.999999957539\n"
     ]
    }
   ],
   "source": [
    "#Displacy displays spacy results in color-coded sequence for similarity score > .95\n",
    "from spacy import displacy\n",
    "from random import randint\n",
    "#to randomly choose one set of tweets\n",
    "randnum = randint(0,1500)\n",
    "#Print out info for each tweet to compare\n",
    "print(\"Name: \" + str(sim_list[randnum][0][0]))\n",
    "print(\"Followers: \" + str(sim_list[randnum][0][1]))\n",
    "print(\"Friends: \" + str(sim_list[randnum][0][2]))\n",
    "print(\"Parts of Speech: \" + str(sim_list[randnum][1]))\n",
    "displacy.render(nlp(sim_list[randnum][0][3]), style='ent', jupyter= True)\n",
    "print(\"Name: \" + str(sim_list[randnum][2][0]))\n",
    "print(\"Followers: \" + str(sim_list[randnum][2][1]))\n",
    "print(\"Friends: \" + str(sim_list[randnum][2][2]))\n",
    "print(\"Parts of Speech: \" + str(sim_list[randnum][3]))\n",
    "displacy.render(nlp(sim_list[randnum][2][3]), style='ent', jupyter= True)\n",
    "\n",
    "print(\"Similarity Score: \" + str(sim_list[randnum][4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: America Returns\n",
      "Followers: 6685\n",
      "Friends: 6306\n",
      "Parts of Speech: PROPN NOUN VERB PROPN NOUN PART VERB DET VERB NOUN PUNCT PRON VERB VERB PART VERB PRON ADP DET PRON PUNCT PRON\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">@Maggiebeast123 @GDouglasJones @MooreSenate Use vinegar to refresh that stink hole. You're going to Need it in a we‚Ä¶ https://t.co/KEfw5PBrMQ</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Defend Liberty\n",
      "Followers: 13372\n",
      "Friends: 10843\n",
      "Parts of Speech: PROPN PROPN PRON VERB PART VERB DET NOUN ADP DET PUNCT PROPN PUNCT PROPN ADP PROPN CCONJ PRON VERB ADV VERB ADV VERB PROPN NOUN PUNCT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    @WMHanlon @pnehlen\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " I struggle to make a Living as a \"\n",
       "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Legal\" Citizen of America\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
       "</mark>\n",
       " yet I don't go around shooting \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Innoc‚Ä¶\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    https://t.co/EirxNx0N6N\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 0.906401580897\n"
     ]
    }
   ],
   "source": [
    "#Displacy displays spacy results in color-coded sequence for similarity score between .90 and .95\n",
    "randnum = randint(0,1500)\n",
    "#Print out info for each tweet to compare\n",
    "print(\"Name: \" + str(sim_list_2[randnum][0][0]))\n",
    "print(\"Followers: \" + str(sim_list_2[randnum][0][1]))\n",
    "print(\"Friends: \" + str(sim_list_2[randnum][0][2]))\n",
    "print(\"Parts of Speech: \" + str(sim_list_2[randnum][1]))\n",
    "displacy.render(nlp(sim_list_2[randnum][0][3]), style='ent', jupyter= True)\n",
    "print(\"Name: \" + str(sim_list_2[randnum][2][0]))\n",
    "print(\"Followers: \" + str(sim_list_2[randnum][2][1]))\n",
    "print(\"Friends: \" + str(sim_list_2[randnum][2][2]))\n",
    "print(\"Parts of Speech: \" + str(sim_list_2[randnum][3]))\n",
    "displacy.render(nlp(sim_list_2[randnum][2][3]), style='ent', jupyter= True)\n",
    "\n",
    "print(\"Similarity Score: \" + str(sim_list_2[randnum][4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
